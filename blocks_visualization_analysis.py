# -*- coding: utf-8 -*-
"""blocks_visualization_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11P2lsK5j81SwYtROzn4t-uBRcjxtgvSY

**PROJETO DISCIPLINA DE ALGORITMOS 1**

Aluno : Thiago Moura da Rocha Bastos

O objetivo desse trabalho e a utilização de dados de densidade óptica de perfis de filmes metálicos obtidos em processo industrial de metalização a vapor, para análise e classificação dos filmes produzido.

Motivação: Sabe-se que a densidade óptica dos filmes metálicos são variáveis essenciais para a qualidade do produto e a sua análise além de possibilitar predições de qualidade do produto formado, possibilita a análise das condições operacionais.
"""

from google.colab import drive
import sys
try:
  drive.mount("/content/drive", force_remount=True)
  root  = '/content/drive/My Drive/projeto'
  sys.path.append(root)
except:
  print('erro encontrado')

try:
  !pip install git+https://github.com/Borda/pyImSegm.git
  !pip install gco-wrapper
  !pip install shap
except:
  print('Erro de instalação shap')

# Commented out IPython magic to ensure Python compatibility.
import pandas
import numpy 
import tensorflow as tf
import datetime
import shap
from typing import List
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
import sklearn.model_selection as skl
import xgboost as xgb
import matplotlib as mpl
import matplotlib.pyplot as plt
from tensorflow.keras import layers
# %matplotlib inline
import os, sys, glob, time
from PIL import Image
import matplotlib.pyplot as plt
from skimage.segmentation import mark_boundaries
import imsegm.utilities.data_io as tl_data
import imsegm.pipelines as segm_pipe
from __future__ import print_function
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
import keras.backend as K

#Coleta de dados da tabela com os valores de Densidade Óptica (DO)
try:
  dbo_blocks= pandas.read_csv('/content/drive/My Drive/projeto/dbo_blocks.csv',error_bad_lines=False,encoding='ISO-8859-1',sep = ';')
except:
  print('Erro de importação da tabela dbo_blocks')

#Transformação da coluna "DateTime" para dados do tipo datetime
dbo_blocks['DateTime'] = pandas.to_datetime(dbo_blocks['DateTime'])

#Transformação do DataFrame em um dicionário de itens, cada item representa uma operação ou filme
aux = numpy.empty_like(dbo_blocks)
blocks_frame = numpy.empty_like(dbo_blocks)
blocks_dic = {}
j = 0
k = 0
for i in range(dbo_blocks.shape[0]):
  if ( i + 1 < dbo_blocks.shape[0]) and (dbo_blocks['Length'][i] < dbo_blocks['Length'][i+1]):
    aux = dbo_blocks.iloc[i]
    blocks_frame[j] = aux
    j +=1
  else:
    blocks_dic[k] = blocks_frame
    blocks_frame = pandas.DataFrame()
    j = 0
    k += 1
blocks_dic = { i: blocks_dic[i] for i in blocks_dic if blocks_dic[i].any != (0,0) }

#Importação de dados com as classificações dos filmes
#tabela com os dados compilados de processo e de qualidade, de onde vem as classes
try:  
  geral = pandas.read_csv('/content/drive/My Drive/projeto/Compilado_1_2.csv', error_bad_lines=False,sep = ';')
except:
  print('Erro de importação tabela geral')
geral = pandas.DataFrame.dropna(geral, axis = 0, how ='all')
geral = geral.reset_index()

#Retirada de conjuntos de valores nulos para comparação com a tabela geral para buscar as classes 
i = 0
k = 0
blocks_dic_new = {}
for i in range(len(blocks_dic)):
  if blocks_dic[i].shape != (0,0):
    blocks_dic_new[k] = blocks_dic[i]
    k += 1

#Os dados de classificação possuem a variável 'DepositStartTime' que é registrada 10 min e 16 s antes do primeiro dado de DO.

deltatime = datetime.timedelta(minutes=10, seconds = 16)
geral['DepositStartTime'] = pandas.to_datetime(geral['DepositStartTime'])

#Comparação entre os dados de tempo do primeiro registro de DO e dados de tempo de DepositStartTime
#Criação de um novo dicionário "bateladas", com os dados de D.O. relacionados a cada classificação

# Gerando um DataFrame para as classes 
l = 0
m = 0
k = 0
y = pandas.DataFrame(columns=['Situação'])
h = pandas.DataFrame(columns=['DepositStartTime'])
batelada = {}
for i in range(len(blocks_dic_new)):
  j = 0
  for j in range(geral.shape[0]):
    l = j
    m = i
    if (geral['DepositStartTime'][l] + deltatime) > blocks_dic_new[m][0][1] and (geral['DepositStartTime'][l] - deltatime) < blocks_dic_new[m][0][1]:
      y.loc[k] = geral['Situação'][l]
      h.loc[k] = geral['DepositStartTime'][l]
      batelada[k] = blocks_dic_new[m]
      k += 1 
results = pandas.concat([y,h], axis = 1)
#Transposição da matriz de densidades ópticas com classificações associadas
i = 0
for i in range(len(batelada)): batelada[i] = pandas.DataFrame.transpose(batelada[i])

#Retirada de variáveis não numéricas
i = 0
for i in range(143):
  batelada[i] = pandas.DataFrame.drop(batelada[i], columns=['ID','Length','DateTime','Fingerprint'])

i = 0
plt.rcParams["figure.figsize"] = (14, 6)
for i in range(len(batelada)):
  plt.bar(batelada[i].columns,len(batelada[i][:][:].values),width= 0.7)

#Retirada de variáveis que não contribuem para o treinamento
i = 0
for i in range(len(batelada)):
  batelada[i] = pandas.DataFrame.drop(batelada[i], columns=['B2','B25','B26','B27','B28','B29','B30','B31'])

#Transformação de dataframe para arrays
batelada_trunc = []
i = 0
for i in range(len(batelada)):
  batelada_trunc.append([])
  batelada_trunc[i] = batelada[i][:][:].values
  batelada_trunc[i] = numpy.asarray(batelada_trunc[i])
batelada_trunc = numpy.asarray(batelada_trunc)

#Transformação das labels "Aprovado" e "Reprovado" para numérico
#print(y)
def filtro(lista:List[str]) -> List[int]:
  if lista == []:
    return []
  else:
    aux = lista.pop(0)
    if aux == "Aprovado":
      return  [1] + filtro(lista)
    elif aux == "Reprovado":
      return [0] + filtro(lista)

y = list(filtro(list(pandas.DataFrame.values.fget(y))))

#Criação de tensores para treinamento de rede neural e tratamento como imagem
tensores = tf.keras.preprocessing.sequence.pad_sequences(batelada_trunc, maxlen= 65, padding = 'post', value = 0, dtype= float, truncating= 'post')

#Transformação das labels de dataframe para numpy array
target = numpy.array(y).astype(numpy.float32)
segments = []
#Amostra supervised segmentation on images
i = 0
for i in range(len(tensores)):
  img = tensores[i]
  #_= plt.imshow(img)
  FIG_SIZE = (8. * numpy.array(img.shape[:2]) / numpy.max(img.shape))[::-1]
  nb_classes = 4
  sp_size = 1
  sp_regul = 0.1
  dict_features = {'color': ['mean', 'std', 'median']}
  #modelo baseado na segmentação da imagme em classes
  model, _ = segm_pipe.estim_model_classes_group([img], nb_classes, sp_size=sp_size, sp_regul=sp_regul, 
                                          dict_features=dict_features, pca_coef=True, model_type='GMM')
  dict_debug = {}
  seg, _ = segm_pipe.segment_color2d_slic_features_model_graphcut(img, model, sp_size=sp_size, sp_regul=sp_regul,
                dict_features=dict_features, gc_regul=1., gc_edge_type='color', debug_visual=dict_debug)
  segments.append(seg)
  fig = plt.figure(figsize=FIG_SIZE)
  print('Exemplo n°: ', str(i))
  plt.imshow(img)
  plt.imshow(seg, cmap=plt.cm.jet)
  _= plt.contour(seg, levels=numpy.unique(seg), colors='w')
  print('Classe: ', 'Aprovado' if y[i] == 1 else 'Reprovado', '\n', numpy.unique(seg, return_counts=True))
  print(seg)

lista_classes = []
i = 0
for i in range(len(segments)): 
  lista_classes.append(numpy.unique(segments[i], return_counts=True)[1])
i = 0
plt.rcParams["figure.figsize"] = (14, 6)
for i in range(len(lista_classes)):
  plt.barh(numpy.unique(segments[i], return_counts=True)[0],lista_classes[i], color = 'green' if y[i] == 1 else 'orange', xerr = True, yerr = True, align = 'center', label = 'Aprovado' if y[i] == 1 else 'Reprovado')
  if i < 2:
    plt.legend()

plt.figure(), plt.imshow(mark_boundaries(tensores[i], dict_debug['slic'], color=(1, 1, 1))), plt.title('SLIC')
plt.figure(), plt.imshow(dict_debug['slic_mean']), plt.title('SLIC mean')
plt.figure(), plt.imshow(dict_debug['img_graph_edges']), plt.title('graph edges')
for i, im_u in enumerate(dict_debug['imgs_unary_cost']):
    plt.figure(), plt.title('unary cost: %i' % i), plt.imshow(im_u)

batch_size = 2
num_classes = 2
epochs = 20

#dimensões de imagem
img_rows, img_cols = 65, 22

# separação do dados em treino e teste
x_train, x_test, y_train, y_test = train_test_split(tensores,target, stratify = target)

#configuração do formato dos dados para adaptação a rede neural

if K.image_data_format() == 'channels_first':
    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)
else:
    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
    input_shape = (img_rows, img_cols, 1)

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

#Construção de modelo de rede neural de forma sequencial
model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))

#compilação da rede neural
model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])
#treinamento da rede
model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(x_test, y_test))

#Análise de desempenho
score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

shap_values_dic = {}

# dados de treino nos quais o modelo foi construído
background = x_train[numpy.random.choice(x_train.shape[0], 20, replace=False)]

# Explicação do modelo para as classes
e1 = shap.DeepExplainer(model, background)
e2 = shap.GradientExplainer(model, background)

shap_values_dic['DeepExplainer'] = {}
shap_values_dic['GradientExplainer']= {}
# plot dos pesos espacialmente distribuídos
i = 4
for i in range(len(x_test)):
  print('Exemplo n°: ', str(i))
  shap_values1 = e1.shap_values(-x_test[i:i+1])
  #print('shap_value - DeepExplainer', str(sum(sum(sum(sum(shap_values1))))))
  shap.image_plot(shap_values1, x_test[i:i+1],labels = y_test[i:i+1], width= 10, hspace=0.2,aspect= 0.5)
  shap_values2 = e2.shap_values(-x_test[i:i+1])
  #print('shap_value - GradientExplainer', str(sum(sum(sum(sum(shap_values2))))))
  #shap.image_plot(shap_values2, x_test[i:i+1],labels = y_test[i:i+1], width= 10, hspace=0.2,aspect= 0.5) 
  shap_values_dic['DeepExplainer'][i] = sum(sum(sum(sum(shap_values1))))
  shap_values_dic['GradientExplainer'][i] = sum(sum(sum(sum(shap_values2))))
#A classe verdadeira é a imagem da direita

i = 0
plt.rcParams["figure.figsize"] = (14, 6)
for i in range(len(shap_values_dic['DeepExplainer'])):
  plt.bar(i,shap_values_dic['DeepExplainer'][i])
  plt.legend(edgecolor = "inherit", labels = y, loc = 'best', shadow = bool,framealpha = 0.5, ncol = 15)
  plt.axes(ylabel = 'DeepExplainer_shap_values', xlabel = 'Example')
i = 0
#for i in range(len(shap_values_dic['DeepExplainer'])):
#  plt.bar(i,shap_values_dic['GradientExplainer'][i])
#  plt.legend(edgecolor = "inherit", labels = y, loc = 'best', shadow = bool,framealpha = 0.5, ncol = 15)
#  plt.axes(ylabel = 'GradientExplainer_shap_values', xlabel = 'Example')

"""**Trabalhos Futuros**



*   Analisar porcentagem das classes mostradas;
*   Determinar thresholds de porcentagem de classe para reprovação do produto
*   Identificação de padrões de falhas e classificação
"""